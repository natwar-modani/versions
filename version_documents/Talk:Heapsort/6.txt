 numerical recipies copyright 
is it acceptable to use code adapted from numerical recipies in c? i don't own a copy, so i can't quote it, but i am led to understand that it is very restrictive in its usage licence.  — philhibbs | talk
that's correct. the code can only be used on one screen if you purchase a single-screen license; distribution is prohibited. deco 00:27, 27 apr 2005 (utc)

 pseudocode question 

i'm fairly certain that the pseudocode in this article does not work on some arrays of odd length.  that is, if length() is odd, then occassionally heapsort() produces an array that is one swap away from sorted.  for example, 
  heapsort([1,2,3]) -> [1,3,2]
and 
  heapsort([2,1,3,5,4]) -> [1,2,4,3,5].
if, in heapsort, i replace the line
    var int start := count / 2 - 1
with
    var int start := count / 2
it seems to correct the bug.
have i missed something?
--quaternion 22:28, 18 feb 2005 (utc)

 the pseudocode works for me.  make sure you are really using integer based variables for the value of start, or take the floor value of count/2.  for example, in perl i said my $start = int($count / 2) - 1; --dustball 02:36, 4 july 2006 (utc)

is it for some reason impractical to implement a quaternary heapsort?

it's not impractical to implement a quaternary heapsort. in fact, i managed to implement an n-ary heapsort algorithm in java. — pguedes

i think there's a bug in the final line of the python program. should it not be called with the first element of the array, 1 instead of with 0?

to my mind o(n log n) is not approximately linear for large n,
but i suppose it depends on your viewpoint. there are sort methods which are linear - e.g pigeon hole sort for a densely populated set of integers, and these
could be expected to run significantly faster.

however, both heapsort and quicksort are, for most practical purposes, amongst the
fastest sorts. note that scrambling the elements before doing a quicksort is often
more effective - as often the elements are almost in order, in which case quicksort is known to be slow. this does not apply to heapsort.

i agree with the o(n log n) statement, and eliminated the claim that it's about linear. scrambling the elements isn't a really effective strategy for improving quicksort, since scrambling involves a lot of cache misses, making it a very slow operation. deco 19:36, 4 nov 2004 (utc)

the article states that an in-place (o(1) auxiliary space) quicksort is possible.  is that true?  don't you need a stack to manage what parts of the array you still need to sort? --ryan stone 15:52, 4 nov 2004 (utc)

oh, i see it now. the data stored on the stack in quicksort is the pivot positions. it is quite possible to compute, rather than store, the pivot positions, in restricted implementations — for example, in a quicksort implementation which always uses the median. i'm not aware of any fast in-place quicksort variant though. deco 19:31, 4 nov 2004 (utc)

there is something i've always wondered about heapsort. when you've created the heap and starts to extract the largest element of it, you swap it with the element with the largest index in the heap to get the value in the right position (ie when you just have created the heap, the first thing you do is to swap the 1st element with the nth, then heapify, then you swap the 1st element with the (n-1)th and heapify and so on). but if you do that you will most of a time get a very low value at the top of the heap (since the value was previously at the bottom of the heap), and since that value is pretty low the siftup will take longer. why don't you instead implement the heap as a min-heap instead of a max-heap? then the head would be at the right position directly (no need to swap) and you could make one of it's children (the element just after it) the head and then heapify. the heapifying would take shorter time on average wouldn't it? i mean, it obvoiusly wouldn't be asymptotically faster, but it would be faster, n'est pas? gkhan 01:21, feb 14, 2005 (utc)
and oh yeah, i realize that the talk-page isn't really the right forum for asking techincal questions, but indulge me gkhan 01:22, feb 14, 2005 (utc)

 note: i removed my previous answer here -- i had the algorithm gkhan was describing completely wrong
 put briefly, the algorithm you describe isn't very effective at all -- assymptotically it's worse than bubble sort.  actually, what you describe is an expensive version of selection sort.
 here's the reason why it's so poor: the heapifying operation takes o(n log n).  what you're suggesting is that we heapify n elements, then n - 1 elements, ... until finally heapifying an array with 1 element(ok, we could skip that, but it doesn't make too much of a difference, and does make the calculations below easier.
 the number of operations we do will thus be o(n log n) + o ( (n - 1) log (n - 1) ) + ... + o ( 1 log 1)
 so it's o ( sum(i = 1 to n) of i log i).  i'm not if that can be simplified, but i do know that sum(i = 1 to n) of i is n(n + 1)/2.  so your algorithm will be worse than o (n ^ 2).
 i don't think that on average, things will be much faster.  let me think about it and see if i can come up with an answer for that.--ryan stone 21:03, 18 feb 2005 (utc)

 well, i've thought about this a bit more, and what i realized was that even if gkhan's algorithm was faster in the average case, it still probably couldn't beat quicksort.  heapsort's greatest advantages over quicksort is its guaranteed o (n log n) and that it's an in-place sort.  if you're willing accept poor performance on certain inputs anyway, you might as well go with quicksort.--ryan stone 02:08, 23 feb 2005 (utc)

 pseudocode question #2 

when getting the child, is multiplying root * 2 enough?
i mean, root = 0, then child = 0?
i'm thinking it should be ((root + 1) * 2) - 1
for the sake of simplicity, the arrays are one-based. however, this should have been explicitly noted and now is. thanks. deco 02:01, 26 jun 2005 (utc)
oops, i was wrong here. it seems like other parts rely on it being zero-based. hmm. deco 28 june 2005 21:17 (utc)

the comment that heapsort is usually faster than mergesort may be a bit dated.

on architectures with a (relatively) small cpu cache and large main memory (e.g. pentiums), heapsort is usually *much* slower than mergesort, when the size of the array being sorted is significantly larger than that of the cache but less than half that of main memory, *because* there are so many cache misses (the penalty is appalling: on my home pc a heapsort of, say, 500,000 32-bit integers takes about twice as long, and of 90,000,000, takes about 10 times as long, as mergesort and quicksort).  

heapsort should *not* be used for large n.

re: the "sorting revisited" link: it just ain't so.  by a stroke of luck, the v8 intel c++ compiler optimizes binary heapsort better than it optimizes quicksort or mergesort (if mergesort is coded in assembler to avoid branch mis-predictions it is slightly faster) (but i'll be damned if i can dream up an efficient way to do the same thing for quicksort!).  the analysis doesn't extend to *large* values of n, which is where heapsort does very badly indeed.  the insertion sort implementation used for the test cases is... non-standard and very inefficient... which knobbles both quicksort and mergesort.  i recommend: *pull* the link.

-james barbetti
this is interesting. i wasn't aware that heapsort had such terrible cache behaviour, but it makes sense considering its access pattern. i can add something regarding this. deco 19:55, 11 july 2005 (utc)

 pseudocode question #3 

how does the following line of code translate to other languages?

 var int root = start, child

how can two variables be assigned to a single varaiable?  can someone please explain how this works and perhaps split this line up into something that can carry over more easily into other languages? 

thank you
-- random heapsort investigator

 presumably, it's like c, where int x, y; declares both x and y as integers. one can make an assignment as well, so int x = 2, y; declares both x and y as integers and sets x to be 2. dysprosia 03:36, 15 august 2006 (utc)

 quicksort not in-place 

isn't it inappropriate to state that an advantage of heapsort over quicksort is that heapsort is in-place? after all, quicksort seems to be easily done in-place as shown in the quicksort article.

quote:

although somewhat slower in practice on most machines than a good implementation of quicksort, it has the advantages of worst-case o(n log n) runtime and being an in-place algorithm.

quicksort is not in place, as the article discusses at some length. quicksort often uses an in-place partition, and has a space-saving tail-recursive variant, but even then it requires ω(log n) space. the quote you gave is actually talking about heapsort, so it's an argument against your claim rather than for. deco 00:30, 6 december 2005 (utc)